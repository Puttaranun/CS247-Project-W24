{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Code is from Tonmoy's discussion notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x1f9fe9a44a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch import Tensor\n",
    "from typing import Type\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from tempfile import TemporaryDirectory\n",
    "import random\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "  device = torch.device('mps')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "\n",
    "print(\"Using\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for training data (only pass the training data through this function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_prep(X,y,sub_sample,average,noise):\n",
    "    \n",
    "    total_X = None\n",
    "    total_y = None\n",
    "    \n",
    "    # Trimming the data (sample,22,1000) -> (sample,22,800)\n",
    "    X = X[:,:,0:800]\n",
    "    print('Shape of X after trimming:',X.shape)\n",
    "    \n",
    "    # Maxpooling the data (sample,22,800) -> (sample,22,800/sub_sample)\n",
    "    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, sub_sample), axis=3)\n",
    "    \n",
    "    \n",
    "    total_X = X_max\n",
    "    total_y = y\n",
    "    print('Shape of X after maxpooling:',total_X.shape)\n",
    "    \n",
    "    # Averaging + noise \n",
    "    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average),axis=3)\n",
    "    X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n",
    "    \n",
    "    total_X = np.vstack((total_X, X_average))\n",
    "    total_y = np.hstack((total_y, y))\n",
    "    print('Shape of X after averaging+noise and concatenating:',total_X.shape)\n",
    "    \n",
    "    # Subsampling\n",
    "    \n",
    "    for i in range(sub_sample):\n",
    "        \n",
    "        X_subsample = X[:, :, i::sub_sample] + \\\n",
    "                            (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
    "        total_X = np.vstack((total_X, X_subsample))\n",
    "        total_y = np.hstack((total_y, y))\n",
    "        \n",
    "    \n",
    "    print('Shape of X after subsampling and concatenating:',total_X.shape)\n",
    "    print('Shape of Y:',total_y.shape)\n",
    "    return total_X,total_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Validation/Testing Data (pass both validation and testing data into this function)\n",
    "\n",
    "Reasoning for why we need to process the val and testing data is because we want the model to test on data similar to the preprocessed training data, so we're not testing oranges when the model has only seen apples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_prep(X):\n",
    "    \n",
    "    total_X = None\n",
    "    \n",
    "    \n",
    "    # Trimming the data (sample,22,1000) -> (sample,22,800)\n",
    "    X = X[:,:,0:800]\n",
    "    print('Shape of X after trimming:',X.shape)\n",
    "    \n",
    "    # Maxpooling the data (sample,22,800) -> (sample,22,800/sub_sample)\n",
    "    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, 2), axis=3)\n",
    "    \n",
    "    \n",
    "    total_X = X_max\n",
    "    print('Shape of X after maxpooling:',total_X.shape)\n",
    "    \n",
    "    return total_X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example on how to use\n",
    "\n",
    "Swap axes section at the end depends on how you use the data. For me, I am doing:\n",
    "\n",
    "Examples x Channels (1) x Electrodes (22) x Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train:  (2115, 22, 1000)\n",
      "y train:  (2115,)\n",
      "Person train+valid:  (2115, 1)\n",
      "X test:  (443, 22, 1000)\n",
      "y test:  (443,)\n",
      "Person test:  (443, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "X_train_valid = np.load(\"C:/Users/awong/OneDrive/Desktop/PythonScripts/C147HW/Final Project/project_data/project/X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"C:/Users/awong/OneDrive/Desktop/PythonScripts/C147HW/Final Project/project_data/project/y_train_valid.npy\")\n",
    "y_train_valid = y_train_valid - 769\n",
    "person_train_valid = np.load(\"C:/Users/awong/OneDrive/Desktop/PythonScripts/C147HW/Final Project/project_data/project/person_train_valid.npy\")\n",
    "\n",
    "# Load test data\n",
    "X_test = np.load(\"C:/Users/awong/OneDrive/Desktop/PythonScripts/C147HW/Final Project/project_data/project/X_test.npy\")\n",
    "y_test = np.load(\"C:/Users/awong/OneDrive/Desktop/PythonScripts/C147HW/Final Project/project_data/project/y_test.npy\")\n",
    "y_test = y_test - 769\n",
    "person_test = np.load(\"C:/Users/awong/OneDrive/Desktop/PythonScripts/C147HW/Final Project/project_data/project/person_test.npy\")\n",
    "\n",
    "# Print shapes\n",
    "print('X train: ', X_train_valid.shape)\n",
    "print('y train: ', y_train_valid.shape)\n",
    "print('Person train+valid: ', person_train_valid.shape)\n",
    "print('X test: ', X_test.shape)\n",
    "print('y test: ', y_test.shape)\n",
    "print('Person test: ', person_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Validation shapes before preprocessing: \n",
      "X train:  (1692, 22, 1000)  Y train:  (1692,)\n",
      "X val:  (423, 22, 1000)  Y val (423,)\n",
      "Shape of X after trimming: (1692, 22, 800)\n",
      "Shape of X after maxpooling: (1692, 22, 400)\n",
      "Shape of X after averaging+noise and concatenating: (3384, 22, 400)\n",
      "Shape of X after subsampling and concatenating: (6768, 22, 400)\n",
      "Shape of Y: (6768,)\n",
      "Shape of X after trimming: (443, 22, 800)\n",
      "Shape of X after maxpooling: (443, 22, 400)\n",
      "Shape of X after trimming: (423, 22, 800)\n",
      "Shape of X after maxpooling: (423, 22, 400)\n",
      "Shape of training set: torch.Size([6768, 22, 400])\n",
      "Shape of validation set: torch.Size([423, 22, 400])\n",
      "Shape of training labels: (6768,)\n",
      "Shape of validation labels: (423,)\n",
      "Shape of training labels after categorical conversion: torch.Size([6768, 4])\n",
      "Shape of validation labels after categorical conversion: torch.Size([423, 4])\n",
      "Shape of test labels after categorical conversion: torch.Size([443, 4])\n",
      "Shape of training set after adding width info: torch.Size([6768, 22, 400, 1])\n",
      "Shape of validation set after adding width info: torch.Size([423, 22, 400, 1])\n",
      "Shape of test set after adding width info: (443, 22, 400, 1)\n",
      "Shape of training set after dimension reshaping: torch.Size([6768, 1, 22, 400])\n",
      "Shape of validation set after dimension reshaping: torch.Size([423, 1, 22, 400])\n",
      "Shape of test set after dimension reshaping: torch.Size([443, 1, 22, 400])\n"
     ]
    }
   ],
   "source": [
    "## Randomly split the train/validation dataset\n",
    "ind_valid = np.random.choice(X_train_valid.shape[0], int(X_train_valid.shape[0]/5), replace=False)\n",
    "ind_train = np.array(list(set(range(X_train_valid.shape[0])).difference(set(ind_valid))))\n",
    "x_valid, y_valid = X_train_valid[ind_valid], y_train_valid[ind_valid]\n",
    "x_train, y_train = X_train_valid[ind_train], y_train_valid[ind_train]\n",
    "print('Training and Validation shapes before preprocessing: ')\n",
    "print('X train: ', x_train.shape, ' Y train: ', y_train.shape)\n",
    "print('X val: ', x_valid.shape, ' Y val', y_valid.shape)\n",
    "\n",
    "# Preprocessing the dataset\n",
    "# pass only training data to train prep, val and test data to test prep\n",
    "\n",
    "x_train,y_train = train_data_prep(x_train,y_train,2,2,True)\n",
    "x_test, x_valid = test_data_prep(X_test), test_data_prep(x_valid) \n",
    "\n",
    "x_train = torch.tensor(x_train).detach().float().to(device)\n",
    "x_valid = torch.tensor(x_valid).detach().float().to(device)\n",
    "print('Shape of training set:',x_train.shape)\n",
    "print('Shape of validation set:',x_valid.shape)\n",
    "print('Shape of training labels:',y_train.shape)\n",
    "print('Shape of validation labels:',y_valid.shape)\n",
    "\n",
    "# Converting the labels to categorical variables for multiclass classification\n",
    "y_train, y_valid, y_test = torch.tensor(y_train).to(device), torch.tensor(y_valid).to(device), torch.tensor(y_test).to(device)\n",
    "y_train = nn.functional.one_hot(y_train.long(), 4)\n",
    "y_valid = nn.functional.one_hot(y_valid.long(), 4)\n",
    "y_test = nn.functional.one_hot(y_test.long(), 4)\n",
    "print('Shape of training labels after categorical conversion:',y_train.shape)\n",
    "print('Shape of validation labels after categorical conversion:',y_valid.shape)\n",
    "print('Shape of test labels after categorical conversion:',y_test.shape)\n",
    "\n",
    "# Adding width of the segment to be 1\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
    "print('Shape of training set after adding width info:',x_train.shape)\n",
    "print('Shape of validation set after adding width info:',x_valid.shape)\n",
    "print('Shape of test set after adding width info:',x_test.shape)\n",
    "\n",
    "\n",
    "# Reshaping the training and validation dataset\n",
    "x_train = np.swapaxes(x_train, 1,3)\n",
    "x_train = np.swapaxes(x_train, 2,3)\n",
    "x_valid = np.swapaxes(x_valid, 1,3)\n",
    "x_valid = np.swapaxes(x_valid, 2,3)\n",
    "x_test = np.swapaxes(x_test, 1,3)\n",
    "x_test = np.swapaxes(x_test, 2,3)\n",
    "x_test = torch.tensor(x_test).detach().float().to(device)\n",
    "print('Shape of training set after dimension reshaping:',x_train.shape)\n",
    "print('Shape of validation set after dimension reshaping:',x_valid.shape)\n",
    "print('Shape of test set after dimension reshaping:',x_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c147proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
